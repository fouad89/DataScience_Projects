{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Analysis of who is more likely to donate in order to target for donations. The data is explored in depth and cleaned. \n",
    "Four Machine Learning Classifiers used and evaluated based on accuracy and time</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/adult.data'\n",
    "donor_df = pd.read_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no columns names in the dataset above,\n",
    "column_names = ['age', 'workclass', 'fnlwgt','education','education-num','marital-status','occupation',\n",
    "                'relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country', 'Income']          \n",
    "donor_df = pd.read_csv(file_name,names = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_df.shape # number of rows, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "donor_df.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing empty space from the Income column\n",
    "donor_df['Income'] = donor_df['Income'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot to visualize the number of donors per Income category\n",
    "plt.figure(figsize=(10,8))\n",
    "pd.DataFrame(donor_df.Income.value_counts()).plot.bar()\n",
    "plt.title(\"Donors by Income\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying category columns & numerical columns\n",
    "cat_cols = [col for col in donor_df.columns if (donor_df[col].dtypes=='object')]\n",
    "num_cols = [col for col in donor_df.columns if (donor_df[col].dtypes !='object')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(cat_cols)} Categorical features:\\n{cat_cols}')\n",
    "print(f'\\nThere are {len(num_cols)} Numerical features:\\n{num_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting income breakdown by category & excluding native_country (due to it having many unique values)\n",
    "\n",
    "income_breakdown = pd.concat([pd.crosstab(donor_df[x],donor_df.Income) for x in cat_cols[:-2]],\n",
    "                            keys=cat_cols[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_breakdown.columns = ['less_50K','more_50K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding percentage column to the breakdown \n",
    "income_breakdown['pct_more_50K'] = round(100 * (income_breakdown['more_50K'] / \n",
    "                                       (income_breakdown['less_50K'] + income_breakdown['more_50K'])),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of hours compared to salary\n",
    "hours_income = pd.crosstab(donor_df['hours-per-week'] >= 40,donor_df.Income)\n",
    "hours_income.columns = ['less_50K','more_50K']\n",
    "hours_income['pct_more50K'] = round(100 * (hours_income['more_50K'] / \n",
    "                                       (hours_income['less_50K'] + hours_income['more_50K'])),2)\n",
    "print(f'Percentage of people making more than 50K by higher or lower than 40 hours per week: \\n\\n{hours_income}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# martial status analysis in focus\n",
    "income_breakdown.loc['marital-status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation matrix \n",
    "def corr_matrix(df):\n",
    "    \"\"\"Plotting the Correlation Matrix of a dataframe\n",
    "    \n",
    "    Parameters:\n",
    "        df: Input dataframe\n",
    "    Output:\n",
    "        Correlation Matrix Plot\n",
    "    \n",
    "    \"\"\"\n",
    "    corr_mat = df.corr()\n",
    "    plt.figure(figsize=(12,8))\n",
    "    mask = np.zeros_like(corr_mat)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(corr_mat,annot=True,mask=mask)\n",
    "    plt.title(\"Correlation Matrix\",fontsize =17)\n",
    "    plt.xticks(rotation=45,fontsize =12)\n",
    "    plt.yticks(rotation=45,fontsize =12)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(donor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the distribution of the age column\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.grid(False)\n",
    "sns.distplot(donor_df.age,bins=20,hist_kws=dict(color='b',edgecolor=\"k\", linewidth=1,alpha=0.3))\n",
    "plt.title(\"Age Distribution Plot\",fontsize=16);\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(xlabel=\"Age\",fontsize=14)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(donor_df.fnlwgt) # the fnlwgt column will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing skewnews and adding skews cols into a list, excluding fnlwgt as the column would be dropped.\n",
    "skewed_cols = [] # list to contain skewed numerical column names\n",
    "for col in num_cols:\n",
    "    # a loop to check skewness of numerical column excluding fnlwgt as it will be dropped\n",
    "    print(f'{col} is skewed by {donor_df[col].skew():.2f}')\n",
    "    if (donor_df[col].skew()<=-1 or donor_df[col].skew()>=1) and col != 'fnlwgt': \n",
    "        # only columns with higher than 1 or lower than -1 will be added to the list of skewed columns\n",
    "        skewed_cols.append(col)\n",
    "\n",
    "print(f'Skewed colums: {skewed_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.title('Skewed Gain & Loss columns before transformation')\n",
    "plt.subplot(121)\n",
    "sns.distplot(donor_df['capital-gain'],kde=False)\n",
    "plt.subplot(122)\n",
    "sns.distplot(donor_df['capital-loss'],kde=False)\n",
    "\n",
    "#plt.title('Skewed Gain & Loss columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to find which transformation gives the best smoothing of skewnewss\n",
    "print(f\"Log Transformation gives: \\n{donor_df[skewed_cols].apply(lambda x: np.log(x+1)).skew()}\")\n",
    "# using sqrt\n",
    "print(f\"\\n\\nSqrt Transformation gives: \\n{donor_df[skewed_cols].apply(lambda x: np.sqrt(x)).skew()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the better transformation seems to be the log transformation\n",
    "donor_df[skewed_cols] = donor_df[skewed_cols].apply(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donor potentials: age <20 or age>70\n",
    "print('Potential donors age <20 or age>70:\\n{}'.format(len(donor_df[(donor_df.age < 20) | (donor_df.age > 70)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_df = donor_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset:\n",
    "<ol>\n",
    "    <li>marital-status column : could combine Married-AF-spouse\t& Married-civ-spouse as one value</li>\n",
    "    <li>workclass col contains a value '?' to replace with a value</li>\n",
    "    <li>there seems to be a week to no correlation between the features</li>\n",
    "    <li>amend the target column 'Income' with 0 & 1? </li>\n",
    "    <li>There are 9 Category columns & 6 numerical</li>\n",
    "    <li>remove the fnlwgt column</li>\n",
    "    <li>use log transformation for capital gain and loss columns</li> \n",
    "\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with ? for occupation from dataset\n",
    "donor_df = donor_df[donor_df.occupation!=' ?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing 500 rows with empty columns\n",
    "donor_df = donor_df[donor_df['native-country'] != ' ?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing fnlwgt column\n",
    "donor_df.drop(['fnlwgt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using MinMaxScaler to transform numerical data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# creating a new dataframe for transformation\n",
    "transformed_df = pd.DataFrame(data=donor_df)\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df[num_cols] = scaler.fit_transform(transformed_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get binary columns\n",
    "cols_binary = [col for col in transformed_df.columns if transformed_df[col].nunique()==2]\n",
    "cols_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform binary columns into 1 for male, 0 for female\n",
    "transformed_df['sex'] = transformed_df['sex'].str.strip().replace(to_replace=[\"Male\",\"Female\"],value=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform income 1 for more than 50K, and 0 for less than 50K\n",
    "transformed_df[\"Income\"] = transformed_df[\"Income\"].replace(to_replace=[\"<=50K\",\">50K\"],value=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check one more time for null values\n",
    "transformed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate target column\n",
    "income_target = transformed_df.Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = transformed_df.drop('Income', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.get_dummies(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(transformed_df,income_target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy \n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cm = confusion_matrix(y_test,predictions)\n",
    "dt_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_plot(model_cm,model_name):\n",
    "    \"\"\"Confusion Matrix Plotting\n",
    "    \n",
    "    INPUT: \n",
    "        model_cm: the model's confusion matrix\n",
    "        model_name: the model's name which could be retrieved by using type(model)__name__\n",
    "    \n",
    "    OUTPUT:\n",
    "        a plot with the model's name in the title of the plot\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10,8));\n",
    "    plt.imshow(model_cm, interpolation='nearest', cmap=plt.cm.coolwarm,alpha=0.3)\n",
    "    classNames = ['Negative','Positive']\n",
    "    plt.title(f'{model_name} Confusion Matrix',fontsize=16)\n",
    "    plt.ylabel('True label',fontsize=14)\n",
    "    plt.xlabel('Predicted label',fontsize=14)\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45,fontsize=12)\n",
    "    plt.yticks(tick_marks, classNames,fontsize=12)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(model_cm[i][j]),fontsize=12,color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot(dt_cm,type(dt_classifier).__name__);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions)) # classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # to measure time required for training the data\n",
    "def model_accuracy(model, X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test):\n",
    "    \"\"\"fitting, predicting the model\n",
    "    \n",
    "    INPUT: model, X,y datasets\n",
    "    \n",
    "    OUPUT: \n",
    "        model_cm: model confusion matrix\n",
    "        model_name: the name of the input model\n",
    "        prints:\n",
    "            - time taken to train the data for the input model\n",
    "            - accuracy score\n",
    "            - classification report\"\"\"\n",
    "    start = time.time() # start time of training data\n",
    "    model.fit(X_train,y_train) # fit the model\n",
    "    stop = time.time() # end end time of training data\n",
    "    y_predict = model.predict(X_test) # use the model to predict\n",
    "    model_name = type(model).__name__ # obtain the model's name\n",
    "    accuracy = accuracy_score(y_test, y_predict) # assess accuracy\n",
    "    model_cm = confusion_matrix(y_test,y_predict)# generate confusion matrix\n",
    "    report = classification_report(y_test,y_predict)\n",
    "    \n",
    "    # print out results\n",
    "    print(f'{model_name} trained in {stop-start:.3f} seconds')\n",
    "    print(f'\\n\\n{model}\\n\\n accuracy: {accuracy*100:.2f}%\\n')\n",
    "    print(f'Classification Report:\\n\\n {report}\\n\\n')\n",
    "    \n",
    "    #cm_plot(model_cm,model_name); # plot the confusion matrix\n",
    "    return [model_cm, model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_accuracy.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using different classifiers and assessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "\n",
    "\n",
    "classifiers = []\n",
    "# add decision trees\n",
    "decision_trees = DecisionTreeClassifier()\n",
    "classifiers.append(decision_trees)\n",
    "# add SVC classifier\n",
    "svc_classifier = SVC()\n",
    "classifiers.append(svc_classifier)\n",
    "\n",
    "# add Adaboost classifier\n",
    "adaboost_classifier = AdaBoostClassifier()\n",
    "classifiers.append(adaboost_classifier)\n",
    "\n",
    "\n",
    "# add random forest classifier\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "classifiers.append(random_forest_classifier)\n",
    "\n",
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in classifiers:\n",
    "    assessment = model_accuracy(model)\n",
    "    cm_plot(assessment[0],assessment[1])\n",
    "    print('*'*80)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation:\n",
    "<ul style=\"color:blue;font-size:25px;\">\n",
    "    <li>AdaBoost Classifier performed with the highest accuracy (85.20%) and the second shortest training time.</li>\n",
    "    <li>Decision Trees perofrmed the worst with 81.21% accuracy but had the shortest training time</li>\n",
    "    <li>SVC performed relatively well when it comes to accuracy but had the longest training time of more that 38s</li>\n",
    "    <li>It is recommended then to go with AdaBoost for this particular project</li>\n",
    "    <li>To improve the model:\n",
    "        <ul>\n",
    "            <li>Unify some of the values under marriage column</li>\n",
    "            <li>Remove the extremes in the age category (suggested thresholds: age less than 20 or higher than 70)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
